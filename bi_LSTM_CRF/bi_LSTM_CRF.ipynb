{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bi-LSTM/CRF.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9bvenbvdoUo"
      },
      "source": [
        "from __future__ import print_function\r\n",
        "from collections import OrderedDict\r\n",
        "\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "from torch.nn import init\r\n",
        "from torch.autograd import Variable\r\n",
        "from torch import autograd\r\n",
        "\r\n",
        "import time\r\n",
        "import _pickle as cPickle\r\n",
        "\r\n",
        "import urllib\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "plt.rcParams['figure.dpi'] = 80\r\n",
        "plt.style.use('seaborn-pastel')\r\n",
        "\r\n",
        "import os\r\n",
        "import sys\r\n",
        "import codecs\r\n",
        "import re\r\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Hs2YuymeELM"
      },
      "source": [
        "#parameters for the Model\r\n",
        "parameters = OrderedDict()\r\n",
        "parameters['train'] = \"./data/eng.train\" #Path to train file\r\n",
        "parameters['dev'] = \"./data/eng.testa\" #Path to test file\r\n",
        "parameters['test'] = \"./data/eng.testb\" #Path to dev file\r\n",
        "parameters['tag_scheme'] = \"BIOES\" #BIO or BIOES\r\n",
        "parameters['lower'] = True # Boolean variable to control lowercasing of words\r\n",
        "parameters['zeros'] =  True # Boolean variable to control replacement of  all digits by 0 \r\n",
        "parameters['char_dim'] = 30 #Char embedding dimension\r\n",
        "parameters['word_dim'] = 100 #Token embedding dimension\r\n",
        "parameters['word_lstm_dim'] = 200 #Token LSTM hidden layer size\r\n",
        "parameters['word_bidirect'] = True #Use a bidirectional LSTM for words\r\n",
        "parameters['embedding_path'] = \"./data/glove.6B.100d.txt\" #Location of pretrained embeddings\r\n",
        "parameters['all_emb'] = 1 #Load all embeddings\r\n",
        "parameters['crf'] =1 #Use CRF (0 to disable)\r\n",
        "parameters['dropout'] = 0.5 #Droupout on the input (0 = no dropout)\r\n",
        "parameters['epoch'] =  50 #Number of epochs to run\"\r\n",
        "parameters['weights'] = \"\" #path to Pretrained for from a previous run\r\n",
        "parameters['name'] = \"self-trained-model\" # Model name\r\n",
        "parameters['gradient_clip']=5.0\r\n",
        "parameters['char_mode']=\"CNN\"\r\n",
        "models_path = \"./models/\" #path to saved models\r\n",
        "\r\n",
        "#GPU\r\n",
        "parameters['use_gpu'] = torch.cuda.is_available() #GPU Check\r\n",
        "use_gpu = parameters['use_gpu']\r\n",
        "\r\n",
        "parameters['reload'] = \"./models/pre-trained-model\" \r\n",
        "\r\n",
        "#Constants\r\n",
        "START_TAG = '<START>'\r\n",
        "STOP_TAG = '<STOP>'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdrTPNr_eG6r"
      },
      "source": [
        "#paths to files \r\n",
        "#To stored mapping file\r\n",
        "mapping_file = './data/mapping.pkl'\r\n",
        "\r\n",
        "#To stored model\r\n",
        "name = parameters['name']\r\n",
        "model_name = models_path + name #get_name(parameters)\r\n",
        "\r\n",
        "if not os.path.exists(models_path):\r\n",
        "    os.makedirs(models_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfYFzetteKth"
      },
      "source": [
        "def zero_digits(s):\r\n",
        "    \"\"\"\r\n",
        "    Replace every digit in a string by a zero.\r\n",
        "    \"\"\"\r\n",
        "    return re.sub('\\d', '0', s)\r\n",
        "\r\n",
        "def load_sentences(path, zeros):\r\n",
        "    \"\"\"\r\n",
        "    Load sentences. A line must contain at least a word and its tag.\r\n",
        "    Sentences are separated by empty lines.\r\n",
        "    \"\"\"\r\n",
        "    sentences = []\r\n",
        "    sentence = []\r\n",
        "    for line in codecs.open(path, 'r', 'utf8'):\r\n",
        "        line = zero_digits(line.rstrip()) if zeros else line.rstrip()\r\n",
        "        if not line:\r\n",
        "            if len(sentence) > 0:\r\n",
        "                if 'DOCSTART' not in sentence[0][0]:\r\n",
        "                    sentences.append(sentence)\r\n",
        "                sentence = []\r\n",
        "        else:\r\n",
        "            word = line.split()\r\n",
        "            assert len(word) >= 2\r\n",
        "            sentence.append(word)\r\n",
        "    if len(sentence) > 0:\r\n",
        "        if 'DOCSTART' not in sentence[0][0]:\r\n",
        "            sentences.append(sentence)\r\n",
        "    return sentences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDMg2sIfeMIf"
      },
      "source": [
        "train_sentences = load_sentences(parameters['train'], parameters['zeros'])\r\n",
        "test_sentences = load_sentences(parameters['test'], parameters['zeros'])\r\n",
        "dev_sentences = load_sentences(parameters['dev'], parameters['zeros'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioPe_lOUefFx",
        "outputId": "09b65b74-287a-4624-9982-0ed558a9feb6"
      },
      "source": [
        "train_sentences[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['EU', 'NNP', 'I-NP', 'I-ORG'],\n",
              " ['rejects', 'VBZ', 'I-VP', 'O'],\n",
              " ['German', 'JJ', 'I-NP', 'I-MISC'],\n",
              " ['call', 'NN', 'I-NP', 'O'],\n",
              " ['to', 'TO', 'I-VP', 'O'],\n",
              " ['boycott', 'VB', 'I-VP', 'O'],\n",
              " ['British', 'JJ', 'I-NP', 'I-MISC'],\n",
              " ['lamb', 'NN', 'I-NP', 'O'],\n",
              " ['.', '.', 'O', 'O']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNVvgt4uehdj",
        "outputId": "a0b1fcf4-4e2d-4aa5-e0b1-b8ebaac941a7"
      },
      "source": [
        "def create_tag(sentences):\r\n",
        "  tags = []\r\n",
        "  for line in sentences:\r\n",
        "    tag = line[-1]\r\n",
        "    if tag == 'O':\r\n",
        "      tags.append('O')\r\n",
        "    if len(tag) >=2:\r\n",
        "      split = tag.split('-')\r\n",
        "      if split[0] == 'I':\r\n",
        "        tags.append('I')\r\n",
        "      if split[0] == 'B':\r\n",
        "        tags.append('B')\r\n",
        "  return tags\r\n",
        "        \r\n",
        "print(create_tag(train_sentences[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['I', 'O', 'I', 'O', 'O', 'O', 'I', 'O', 'O']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnYwS9_Vej9Q",
        "outputId": "225d0c4b-23e8-4d8a-8329-f13bdad40aef"
      },
      "source": [
        "def create_sentence(sentence_array):\r\n",
        "  sentence = []\r\n",
        "  for line in sentence_array:\r\n",
        "    word = line[0]\r\n",
        "    sentence.append(word)\r\n",
        "  return sentence\r\n",
        "\r\n",
        "print(create_sentence(train_sentences[0]))\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kk7WUxYKemVv",
        "outputId": "b7d88cd5-5e32-4f36-e14f-20c4639a0a79"
      },
      "source": [
        "def create_prepared_train_data():\r\n",
        "  prepared_train_data = []\r\n",
        "  for i in range(len(train_sentences)):\r\n",
        "    sentence = create_sentence(train_sentences[i])\r\n",
        "    tag = create_tag(train_sentences[i])\r\n",
        "    one_data_tupple = (sentence, tag)\r\n",
        "    prepared_train_data.append(one_data_tupple)\r\n",
        "  return prepared_train_data\r\n",
        "\r\n",
        "create_prepared_train_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.'],\n",
              "  ['I', 'O', 'I', 'O', 'O', 'O', 'I', 'O', 'O']),\n",
              " (['Peter', 'Blackburn'], ['I', 'I']),\n",
              " (['BRUSSELS', '0000-00-00'], ['I', 'O']),\n",
              " (['The',\n",
              "   'European',\n",
              "   'Commission',\n",
              "   'said',\n",
              "   'on',\n",
              "   'Thursday',\n",
              "   'it',\n",
              "   'disagreed',\n",
              "   'with',\n",
              "   'German',\n",
              "   'advice',\n",
              "   'to',\n",
              "   'consumers',\n",
              "   'to',\n",
              "   'shun',\n",
              "   'British',\n",
              "   'lamb',\n",
              "   'until',\n",
              "   'scientists',\n",
              "   'determine',\n",
              "   'whether',\n",
              "   'mad',\n",
              "   'cow',\n",
              "   'disease',\n",
              "   'can',\n",
              "   'be',\n",
              "   'transmitted',\n",
              "   'to',\n",
              "   'sheep',\n",
              "   '.'],\n",
              "  ['O',\n",
              "   'I',\n",
              "   'I',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'I',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'I',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O']),\n",
              " (['Germany',\n",
              "   \"'s\",\n",
              "   'representative',\n",
              "   'to',\n",
              "   'the',\n",
              "   'European',\n",
              "   'Union',\n",
              "   \"'s\",\n",
              "   'veterinary',\n",
              "   'committee',\n",
              "   'Werner',\n",
              "   'Zwingmann',\n",
              "   'said',\n",
              "   'on',\n",
              "   'Wednesday',\n",
              "   'consumers',\n",
              "   'should',\n",
              "   'buy',\n",
              "   'sheepmeat',\n",
              "   'from',\n",
              "   'countries',\n",
              "   'other',\n",
              "   'than',\n",
              "   'Britain',\n",
              "   'until',\n",
              "   'the',\n",
              "   'scientific',\n",
              "   'advice',\n",
              "   'was',\n",
              "   'clearer',\n",
              "   '.'],\n",
              "  ['I',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'I',\n",
              "   'I',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'I',\n",
              "   'I',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'I',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O']),\n",
              " (['\"',\n",
              "   'We',\n",
              "   'do',\n",
              "   \"n't\",\n",
              "   'support',\n",
              "   'any',\n",
              "   'such',\n",
              "   'recommendation',\n",
              "   'because',\n",
              "   'we',\n",
              "   'do',\n",
              "   \"n't\",\n",
              "   'see',\n",
              "   'any',\n",
              "   'grounds',\n",
              "   'for',\n",
              "   'it',\n",
              "   ',',\n",
              "   '\"',\n",
              "   'the',\n",
              "   'Commission',\n",
              "   \"'s\",\n",
              "   'chief',\n",
              "   'spokesman',\n",
              "   'Nikolaus',\n",
              "   'van',\n",
              "   'der',\n",
              "   'Pas',\n",
              "   'told',\n",
              "   'a',\n",
              "   'news',\n",
              "   'briefing',\n",
              "   '.'],\n",
              "  ['O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'I',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'I',\n",
              "   'I',\n",
              "   'I',\n",
              "   'I',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O']),\n",
              " (['He',\n",
              "   'said',\n",
              "   'further',\n",
              "   'scientific',\n",
              "   'study',\n",
              "   'was',\n",
              "   'required',\n",
              "   'and',\n",
              "   'if',\n",
              "   'it',\n",
              "   'was',\n",
              "   'found',\n",
              "   'that',\n",
              "   'action',\n",
              "   'was',\n",
              "   'needed',\n",
              "   'it',\n",
              "   'should',\n",
              "   'be',\n",
              "   'taken',\n",
              "   'by',\n",
              "   'the',\n",
              "   'European',\n",
              "   'Union',\n",
              "   '.'],\n",
              "  ['O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'I',\n",
              "   'I',\n",
              "   'O']),\n",
              " (['He',\n",
              "   'said',\n",
              "   'a',\n",
              "   'proposal',\n",
              "   'last',\n",
              "   'month',\n",
              "   'by',\n",
              "   'EU',\n",
              "   'Farm',\n",
              "   'Commissioner',\n",
              "   'Franz',\n",
              "   'Fischler',\n",
              "   'to',\n",
              "   'ban',\n",
              "   'sheep',\n",
              "   'brains',\n",
              "   ',',\n",
              "   'spleens',\n",
              "   'and',\n",
              "   'spinal',\n",
              "   'cords',\n",
              "   'from',\n",
              "   'the',\n",
              "   'human',\n",
              "   'and',\n",
              "   'animal',\n",
              "   'food',\n",
              "   'chains',\n",
              "   'was',\n",
              "   'a',\n",
              "   'highly',\n",
              "   'specific',\n",
              "   'and',\n",
              "   'precautionary',\n",
              "   'move',\n",
              "   'to',\n",
              "   'protect',\n",
              "   'human',\n",
              "   'health',\n",
              "   '.'],\n",
              "  ['O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'I',\n",
              "   'O',\n",
              "   'O',\n",
              "   'I',\n",
              "   'I',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O']),\n",
              " (['Fischler',\n",
              "   'proposed',\n",
              "   'EU-wide',\n",
              "   'measures',\n",
              "   'after',\n",
              "   'reports',\n",
              "   'from',\n",
              "   'Britain',\n",
              "   'and',\n",
              "   'France',\n",
              "   'that',\n",
              "   'under',\n",
              "   'laboratory',\n",
              "   'conditions',\n",
              "   'sheep',\n",
              "   'could',\n",
              "   'contract',\n",
              "   'Bovine',\n",
              "   'Spongiform',\n",
              "   'Encephalopathy',\n",
              "   '(',\n",
              "   'BSE',\n",
              "   ')',\n",
              "   '--',\n",
              "   'mad',\n",
              "   'cow',\n",
              "   'disease',\n",
              "   '.'],\n",
              "  ['I',\n",
              "   'O',\n",
              "   'I',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'I',\n",
              "   'O',\n",
              "   'I',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'I',\n",
              "   'I',\n",
              "   'I',\n",
              "   'O',\n",
              "   'I',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O']),\n",
              " (['But',\n",
              "   'Fischler',\n",
              "   'agreed',\n",
              "   'to',\n",
              "   'review',\n",
              "   'his',\n",
              "   'proposal',\n",
              "   'after',\n",
              "   'the',\n",
              "   'EU',\n",
              "   \"'s\",\n",
              "   'standing',\n",
              "   'veterinary',\n",
              "   'committee',\n",
              "   ',',\n",
              "   'mational',\n",
              "   'animal',\n",
              "   'health',\n",
              "   'officials',\n",
              "   ',',\n",
              "   'questioned',\n",
              "   'if',\n",
              "   'such',\n",
              "   'action',\n",
              "   'was',\n",
              "   'justified',\n",
              "   'as',\n",
              "   'there',\n",
              "   'was',\n",
              "   'only',\n",
              "   'a',\n",
              "   'slight',\n",
              "   'risk',\n",
              "   'to',\n",
              "   'human',\n",
              "   'health',\n",
              "   '.'],\n",
              "  ['O',\n",
              "   'I',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'I',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O']),\n",
              " (['Spanish',\n",
              "   'Farm',\n",
              "   'Minister',\n",
              "   'Loyola',\n",
              "   'de',\n",
              "   'Palacio',\n",
              "   'had',\n",
              "   'earlier',\n",
              "   'accused',\n",
              "   'Fischler',\n",
              "   'at',\n",
              "   'an',\n",
              "   'EU',\n",
              "   'farm',\n",
              "   'ministers',\n",
              "   \"'\",\n",
              "   'meeting',\n",
              "   'of',\n",
              "   'causing',\n",
              "   'unjustified',\n",
              "   'alarm',\n",
              "   'through',\n",
              "   '\"',\n",
              "   'dangerous',\n",
              "   'generalisation',\n",
              "   '.',\n",
              "   '\"'],\n",
              "  ['I',\n",
              "   'O',\n",
              "   'O',\n",
              "   'I',\n",
              "   'I',\n",
              "   'I',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'I',\n",
              "   'O',\n",
              "   'O',\n",
              "   'I',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O']),\n",
              " (['.'], ['O']),\n",
              " (['Only',\n",
              "   'France',\n",
              "   'and',\n",
              "   'Britain',\n",
              "   'backed',\n",
              "   'Fischler',\n",
              "   \"'s\",\n",
              "   'proposal',\n",
              "   '.'],\n",
              "  ['O', 'I', 'O', 'I', 'O', 'I', 'O', 'O', 'O']),\n",
              " (['The',\n",
              "   'EU',\n",
              "   \"'s\",\n",
              "   'scientific',\n",
              "   'veterinary',\n",
              "   'and',\n",
              "   'multidisciplinary',\n",
              "   'committees',\n",
              "   'are',\n",
              "   'due',\n",
              "   'to',\n",
              "   're-examine',\n",
              "   'the',\n",
              "   'issue',\n",
              "   'early',\n",
              "   'next',\n",
              "   'month',\n",
              "   'and',\n",
              "   'make',\n",
              "   'recommendations',\n",
              "   'to',\n",
              "   'the',\n",
              "   'senior',\n",
              "   'veterinary',\n",
              "   'officials',\n",
              "   '.'],\n",
              "  ['O',\n",
              "   'I',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O']),\n",
              " (['Sheep',\n",
              "   'have',\n",
              "   'long',\n",
              "   'been',\n",
              "   'known',\n",
              "   'to',\n",
              "   'contract',\n",
              "   'scrapie',\n",
              "   ',',\n",
              "   'a',\n",
              "   'brain-wasting',\n",
              "   'disease',\n",
              "   'similar',\n",
              "   'to',\n",
              "   'BSE',\n",
              "   'which',\n",
              "   'is',\n",
              "   'believed',\n",
              "   'to',\n",
              "   'have',\n",
              "   'been',\n",
              "   'transferred',\n",
              "   'to',\n",
              "   'cattle',\n",
              "   'through',\n",
              "   'feed',\n",
              "   'containing',\n",
              "   'animal',\n",
              "   'waste',\n",
              "   '.'],\n",
              "  ['O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'I',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O']),\n",
              " (['British',\n",
              "   'farmers',\n",
              "   'denied',\n",
              "   'on',\n",
              "   'Thursday',\n",
              "   'there',\n",
              "   'was',\n",
              "   'any',\n",
              "   'danger',\n",
              "   'to',\n",
              "   'human',\n",
              "   'health',\n",
              "   'from',\n",
              "   'their',\n",
              "   'sheep',\n",
              "   ',',\n",
              "   'but',\n",
              "   'expressed',\n",
              "   'concern',\n",
              "   'that',\n",
              "   'German',\n",
              "   'government',\n",
              "   'advice',\n",
              "   'to',\n",
              "   'consumers',\n",
              "   'to',\n",
              "   'avoid',\n",
              "   'British',\n",
              "   'lamb',\n",
              "   'might',\n",
              "   'influence',\n",
              "   'consumers',\n",
              "   'across',\n",
              "   'Europe',\n",
              "   '.'],\n",
              "  ['I',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'I',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'I',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'I',\n",
              "   'O']),\n",
              " (['\"',\n",
              "   'What',\n",
              "   'we',\n",
              "   'have',\n",
              "   'to',\n",
              "   'be',\n",
              "   'extremely',\n",
              "   'careful',\n",
              "   'of',\n",
              "   'is',\n",
              "   'how',\n",
              "   'other',\n",
              "   'countries',\n",
              "   'are',\n",
              "   'going',\n",
              "   'to',\n",
              "   'take',\n",
              "   'Germany',\n",
              "   \"'s\",\n",
              "   'lead',\n",
              "   ',',\n",
              "   '\"',\n",
              "   'Welsh',\n",
              "   'National',\n",
              "   'Farmers',\n",
              "   \"'\",\n",
              "   'Union',\n",
              "   '(',\n",
              "   'NFU',\n",
              "   ')',\n",
              "   'chairman',\n",
              "   'John',\n",
              "   'Lloyd',\n",
              "   'Jones',\n",
              "   'said',\n",
              "   'on',\n",
              "   'BBC',\n",
              "   'radio',\n",
              "   '.'],\n",
              "  ['O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'I',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'I',\n",
              "   'I',\n",
              "   'I',\n",
              "   'I',\n",
              "   'I',\n",
              "   'O',\n",
              "   'I',\n",
              "   'O',\n",
              "   'O',\n",
              "   'I',\n",
              "   'I',\n",
              "   'I',\n",
              "   'O',\n",
              "   'O',\n",
              "   'I',\n",
              "   'I',\n",
              "   'O']),\n",
              " (['Bonn',\n",
              "   'has',\n",
              "   'led',\n",
              "   'efforts',\n",
              "   'to',\n",
              "   'protect',\n",
              "   'public',\n",
              "   'health',\n",
              "   'after',\n",
              "   'consumer',\n",
              "   'confidence',\n",
              "   'collapsed',\n",
              "   'in',\n",
              "   'March',\n",
              "   'after',\n",
              "   'a',\n",
              "   'British',\n",
              "   'report',\n",
              "   'suggested',\n",
              "   'humans',\n",
              "   'could',\n",
              "   'contract',\n",
              "   'an',\n",
              "   'illness',\n",
              "   'similar',\n",
              "   'to',\n",
              "   'mad',\n",
              "   'cow',\n",
              "   'disease',\n",
              "   'by',\n",
              "   'eating',\n",
              "   'contaminated',\n",
              "   'beef',\n",
              "   '.'],\n",
              "  ['I',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'I',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O']),\n",
              " (['Germany',\n",
              "   'imported',\n",
              "   '00,000',\n",
              "   'sheep',\n",
              "   'from',\n",
              "   'Britain',\n",
              "   'last',\n",
              "   'year',\n",
              "   ',',\n",
              "   'nearly',\n",
              "   'half',\n",
              "   'of',\n",
              "   'total',\n",
              "   'imports',\n",
              "   '.'],\n",
              "  ['I', 'O', 'O', 'O', 'O', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']),\n",
              " (['It',\n",
              "   'brought',\n",
              "   'in',\n",
              "   '0,000',\n",
              "   'tonnes',\n",
              "   'of',\n",
              "   'British',\n",
              "   'mutton',\n",
              "   ',',\n",
              "   'some',\n",
              "   '00',\n",
              "   'percent',\n",
              "   'of',\n",
              "   'overall',\n",
              "   'imports',\n",
              "   '.'],\n",
              "  ['O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'I',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O',\n",
              "   'O']),\n",
              " (['Rare',\n",
              "   'Hendrix',\n",
              "   'song',\n",
              "   'draft',\n",
              "   'sells',\n",
              "   'for',\n",
              "   'almost',\n",
              "   '$',\n",
              "   '00,000',\n",
              "   '.'],\n",
              "  ['O', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']),\n",
              " (['LONDON', '0000-00-00'], ['I', 'O'])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JG88A3hcerU1",
        "outputId": "0b574aa9-218f-44a9-e0a7-04f83482b075"
      },
      "source": [
        "# Author: Robert Guthrie\r\n",
        "\r\n",
        "import torch\r\n",
        "import torch.autograd as autograd\r\n",
        "import torch.nn as nn\r\n",
        "import torch.optim as optim\r\n",
        "\r\n",
        "torch.manual_seed(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f240b1ca430>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezalrR7-etg_"
      },
      "source": [
        "def argmax(vec):\r\n",
        "    # return the argmax as a python int\r\n",
        "    _, idx = torch.max(vec, 1)\r\n",
        "    return idx.item()\r\n",
        "\r\n",
        "\r\n",
        "def prepare_sequence(seq, to_ix):\r\n",
        "    idxs = [to_ix[w] for w in seq]\r\n",
        "    return torch.tensor(idxs, dtype=torch.long)\r\n",
        "\r\n",
        "\r\n",
        "# Compute log sum exp in a numerically stable way for the forward algorithm\r\n",
        "def log_sum_exp(vec):\r\n",
        "    max_score = vec[0, argmax(vec)]\r\n",
        "    max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\r\n",
        "    return max_score + \\\r\n",
        "        torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3YyjfbKev6v"
      },
      "source": [
        "class BiLSTM_CRF(nn.Module):\r\n",
        "\r\n",
        "    def __init__(self, vocab_size, tag_to_ix, embedding_dim, hidden_dim):\r\n",
        "        super(BiLSTM_CRF, self).__init__()\r\n",
        "        self.embedding_dim = embedding_dim\r\n",
        "        self.hidden_dim = hidden_dim\r\n",
        "        self.vocab_size = vocab_size\r\n",
        "        self.tag_to_ix = tag_to_ix\r\n",
        "        self.tagset_size = len(tag_to_ix)\r\n",
        "\r\n",
        "        self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\r\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2,\r\n",
        "                            num_layers=1, bidirectional=True)\r\n",
        "\r\n",
        "        # Maps the output of the LSTM into tag space.\r\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size)\r\n",
        "\r\n",
        "        # Matrix of transition parameters.  Entry i,j is the score of\r\n",
        "        # transitioning *to* i *from* j.\r\n",
        "        self.transitions = nn.Parameter(\r\n",
        "            torch.randn(self.tagset_size, self.tagset_size))\r\n",
        "\r\n",
        "        # These two statements enforce the constraint that we never transfer\r\n",
        "        # to the start tag and we never transfer from the stop tag\r\n",
        "        self.transitions.data[tag_to_ix[START_TAG], :] = -10000\r\n",
        "        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\r\n",
        "\r\n",
        "        self.hidden = self.init_hidden()\r\n",
        "\r\n",
        "    def init_hidden(self):\r\n",
        "        return (torch.randn(2, 1, self.hidden_dim // 2),\r\n",
        "                torch.randn(2, 1, self.hidden_dim // 2))\r\n",
        "\r\n",
        "    def _forward_alg(self, feats):\r\n",
        "        # Do the forward algorithm to compute the partition function\r\n",
        "        init_alphas = torch.full((1, self.tagset_size), -10000.)\r\n",
        "        # START_TAG has all of the score.\r\n",
        "        init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\r\n",
        "\r\n",
        "        # Wrap in a variable so that we will get automatic backprop\r\n",
        "        forward_var = init_alphas\r\n",
        "\r\n",
        "        # Iterate through the sentence\r\n",
        "        for feat in feats:\r\n",
        "            alphas_t = []  # The forward tensors at this timestep\r\n",
        "            for next_tag in range(self.tagset_size):\r\n",
        "                # broadcast the emission score: it is the same regardless of\r\n",
        "                # the previous tag\r\n",
        "                emit_score = feat[next_tag].view(\r\n",
        "                    1, -1).expand(1, self.tagset_size)\r\n",
        "                # the ith entry of trans_score is the score of transitioning to\r\n",
        "                # next_tag from i\r\n",
        "                trans_score = self.transitions[next_tag].view(1, -1)\r\n",
        "                # The ith entry of next_tag_var is the value for the\r\n",
        "                # edge (i -> next_tag) before we do log-sum-exp\r\n",
        "                next_tag_var = forward_var + trans_score + emit_score\r\n",
        "                # The forward variable for this tag is log-sum-exp of all the\r\n",
        "                # scores.\r\n",
        "                alphas_t.append(log_sum_exp(next_tag_var).view(1))\r\n",
        "            forward_var = torch.cat(alphas_t).view(1, -1)\r\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\r\n",
        "        alpha = log_sum_exp(terminal_var)\r\n",
        "        return alpha\r\n",
        "\r\n",
        "    def _get_lstm_features(self, sentence):\r\n",
        "        self.hidden = self.init_hidden()\r\n",
        "        embeds = self.word_embeds(sentence).view(len(sentence), 1, -1)\r\n",
        "        lstm_out, self.hidden = self.lstm(embeds, self.hidden)\r\n",
        "        lstm_out = lstm_out.view(len(sentence), self.hidden_dim)\r\n",
        "        lstm_feats = self.hidden2tag(lstm_out)\r\n",
        "        return lstm_feats\r\n",
        "\r\n",
        "    def _score_sentence(self, feats, tags):\r\n",
        "        # Gives the score of a provided tag sequence\r\n",
        "        score = torch.zeros(1)\r\n",
        "        tags = torch.cat([torch.tensor([self.tag_to_ix[START_TAG]], dtype=torch.long), tags])\r\n",
        "        for i, feat in enumerate(feats):\r\n",
        "            score = score + \\\r\n",
        "                self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\r\n",
        "        score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]\r\n",
        "        return score\r\n",
        "\r\n",
        "    def _viterbi_decode(self, feats):\r\n",
        "        backpointers = []\r\n",
        "\r\n",
        "        # Initialize the viterbi variables in log space\r\n",
        "        init_vvars = torch.full((1, self.tagset_size), -10000.)\r\n",
        "        init_vvars[0][self.tag_to_ix[START_TAG]] = 0\r\n",
        "\r\n",
        "        # forward_var at step i holds the viterbi variables for step i-1\r\n",
        "        forward_var = init_vvars\r\n",
        "        for feat in feats:\r\n",
        "            bptrs_t = []  # holds the backpointers for this step\r\n",
        "            viterbivars_t = []  # holds the viterbi variables for this step\r\n",
        "\r\n",
        "            for next_tag in range(self.tagset_size):\r\n",
        "                # next_tag_var[i] holds the viterbi variable for tag i at the\r\n",
        "                # previous step, plus the score of transitioning\r\n",
        "                # from tag i to next_tag.\r\n",
        "                # We don't include the emission scores here because the max\r\n",
        "                # does not depend on them (we add them in below)\r\n",
        "                next_tag_var = forward_var + self.transitions[next_tag]\r\n",
        "                best_tag_id = argmax(next_tag_var)\r\n",
        "                bptrs_t.append(best_tag_id)\r\n",
        "                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\r\n",
        "            # Now add in the emission scores, and assign forward_var to the set\r\n",
        "            # of viterbi variables we just computed\r\n",
        "            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\r\n",
        "            backpointers.append(bptrs_t)\r\n",
        "\r\n",
        "        # Transition to STOP_TAG\r\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\r\n",
        "        best_tag_id = argmax(terminal_var)\r\n",
        "        path_score = terminal_var[0][best_tag_id]\r\n",
        "\r\n",
        "        # Follow the back pointers to decode the best path.\r\n",
        "        best_path = [best_tag_id]\r\n",
        "        for bptrs_t in reversed(backpointers):\r\n",
        "            best_tag_id = bptrs_t[best_tag_id]\r\n",
        "            best_path.append(best_tag_id)\r\n",
        "        # Pop off the start tag (we dont want to return that to the caller)\r\n",
        "        start = best_path.pop()\r\n",
        "        assert start == self.tag_to_ix[START_TAG]  # Sanity check\r\n",
        "        best_path.reverse()\r\n",
        "        return path_score, best_path\r\n",
        "\r\n",
        "    def neg_log_likelihood(self, sentence, tags):\r\n",
        "        feats = self._get_lstm_features(sentence)\r\n",
        "        forward_score = self._forward_alg(feats)\r\n",
        "        gold_score = self._score_sentence(feats, tags)\r\n",
        "        return forward_score - gold_score\r\n",
        "\r\n",
        "    def forward(self, sentence):  # dont confuse this with _forward_alg above.\r\n",
        "        # Get the emission scores from the BiLSTM\r\n",
        "        lstm_feats = self._get_lstm_features(sentence)\r\n",
        "\r\n",
        "        # Find the best path, given the features.\r\n",
        "        score, tag_seq = self._viterbi_decode(lstm_feats)\r\n",
        "        return score, tag_seq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLnS5h22ezvm",
        "outputId": "c8c3b35d-fca2-4379-b91a-77875a041429"
      },
      "source": [
        "tra_data = create_prepared_train_data()\r\n",
        "tra_data[0]\r\n",
        "print(len(tra_data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "22\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqB4-s5Se2Uu",
        "outputId": "15979bb7-6620-4c2f-8575-96866f122097"
      },
      "source": [
        "START_TAG = \"<START>\"\r\n",
        "STOP_TAG = \"<STOP>\"\r\n",
        "EMBEDDING_DIM = 5\r\n",
        "HIDDEN_DIM = 4\r\n",
        "\r\n",
        "# Make up some training data\r\n",
        "training_data = create_prepared_train_data()\r\n",
        "\r\n",
        "word_to_ix = {}\r\n",
        "for sentence, tags in training_data:\r\n",
        "    for word in sentence:\r\n",
        "        if word not in word_to_ix:\r\n",
        "            word_to_ix[word] = len(word_to_ix)\r\n",
        "\r\n",
        "tag_to_ix = {\"B\": 0, \"I\": 1, \"O\": 2, START_TAG: 3, STOP_TAG: 4}\r\n",
        "\r\n",
        "model = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM)\r\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)\r\n",
        "\r\n",
        "# Check predictions before training\r\n",
        "with torch.no_grad():\r\n",
        "    precheck_sent = prepare_sequence(training_data[0][0], word_to_ix)\r\n",
        "    precheck_tags = torch.tensor([tag_to_ix[t] for t in training_data[0][1]], dtype=torch.long)\r\n",
        "    print(model(precheck_sent))\r\n",
        "\r\n",
        "# Make sure prepare_sequence from earlier in the LSTM section is loaded\r\n",
        "for epoch in range(\r\n",
        "        300):  # again, normally you would NOT do 300 epochs, it is toy data\r\n",
        "    for sentence, tags in training_data:\r\n",
        "        # Step 1. Remember that Pytorch accumulates gradients.\r\n",
        "        # We need to clear them out before each instance\r\n",
        "        model.zero_grad()\r\n",
        "\r\n",
        "        # Step 2. Get our inputs ready for the network, that is,\r\n",
        "        # turn them into Tensors of word indices.\r\n",
        "        sentence_in = prepare_sequence(sentence, word_to_ix)\r\n",
        "        targets = torch.tensor([tag_to_ix[t] for t in tags], dtype=torch.long)\r\n",
        "\r\n",
        "        # Step 3. Run our forward pass.\r\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets)\r\n",
        "\r\n",
        "        # Step 4. Compute the loss, gradients, and update the parameters by\r\n",
        "        # calling optimizer.step()\r\n",
        "        loss.backward()\r\n",
        "        optimizer.step()\r\n",
        "\r\n",
        "# Check predictions after training\r\n",
        "with torch.no_grad():\r\n",
        "    precheck_sent = prepare_sequence(training_data[0][0], word_to_ix)\r\n",
        "    print(model(precheck_sent))\r\n",
        "# We got it!"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(tensor(11.6138), [0, 2, 1, 0, 2, 1, 0, 2, 0])\n",
            "(tensor(55.4297), [1, 2, 1, 2, 2, 2, 1, 2, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9ZGLhMyK07M"
      },
      "source": [
        "REFERANSLAR:\r\n",
        "[1] https://pytorch.org/tutorials/beginner/nlp/advanced_tutorial.html\r\n",
        "\r\n",
        "[2] https://github.com/jayavardhanr/End-to-end-Sequence-Labeling-via-Bi-directional-LSTM-CNNs-CRF-Tutorial/blob/master/Named_Entity_Recognition-LSTM-CNN-CRF-Tutorial.ipynb\r\n"
      ]
    }
  ]
}